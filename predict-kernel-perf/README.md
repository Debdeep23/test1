# GPU Kernel Performance Prediction

This directory contains performance prediction models that predict GPU kernel execution times across different GPU architectures using data collected from the `gpu-perf` pipeline.

## Overview

The models predict how a kernel that runs on one GPU (source GPU) will perform when executed on a different GPU (target GPU). Two complementary approaches are provided:

1. **Analytical Model** - Physics-based roofline model using occupancy and hardware characteristics
2. **Machine Learning Models** - Data-driven models trained on kernel benchmarks

## Modeling Approaches

### Analytical Model (`analytical_model_occupancy.py`)

Uses a roofline-based analytical model that predicts performance by:
- Computing arithmetic intensity (FLOPs/BYTES ratio)
- Calculating GPU occupancy based on register and shared memory usage
- Applying roofline bounds (compute vs memory bottlenecks)
- Scaling performance using efficiency factors and hardware specifications

**Key features:**
- No training required
- Interpretable predictions based on hardware limits
- Works with limited data points

### Machine Learning Models (`ml_baseline.py`)

Trains multiple regression models on kernel benchmark data:
- Linear Regression, Ridge, Lasso
- Support Vector Regression (SVR)
- Random Forest, Gradient Boosting
- K-Nearest Neighbors (KNN)

**Key features:**
- Learns patterns from historical kernel executions
- Uses kernel features (FLOPs, BYTES, registers, shared memory) and GPU specs
- Provides comparative analysis across different ML algorithms

## Evaluation Experiments

Both models are evaluated on three scenarios:

**Experiment 1: Same kernel, same config, new GPU**
- Predict performance on a held-out GPU (Titan V)
- Tests cross-GPU generalization

**Experiment 2: Same kernel, new configs, same GPUs**
- Predict performance for unseen problem sizes
- Tests scaling behavior within known kernels

**Experiment 3: New but related kernels**
- Predict performance for entirely new kernels (matmul_tiled, shared_transpose, etc.)
- Tests kernel-to-kernel generalization

## Usage

### Prerequisites
Place the following files in `predict-kernel-perf/data/`:
- `runs_2080ti_final.csv`
- `runs_4070_final.csv`
- `runs_titanv_final.csv`
- `runs_titanx_final.csv`
- `gpu_metrics.json`

These files are generated by the data collection pipeline in `gpu-perf/`.

### Running Models

**Analytical Model:**
```bash
cd predict-kernel-perf/scripts
python3 analytical_model_occupancy.py
```

**ML Models:**
```bash
cd predict-kernel-perf/scripts
python3 ml_baseline.py
```

## Outputs

Both scripts generate CSV files with predictions and metrics:

**Analytical Model** (`analytic_model_outputs/`):
- `cross_gpu_predictions.csv` - All cross-GPU predictions
- `exp1_same_config_new_gpu.csv` - Experiment 1 results
- `exp2_new_configs_same_gpus.csv` - Experiment 2 results
- `exp3a_*`, `exp3b_*` - Experiment 3 results with kernel-level metrics

**ML Models** (`ml_outputs/`):
- `exp1_*_[model]_predictions.csv` - Per-model predictions for each experiment
- `exp1_*_[model]_kernel_metrics.csv` - Per-kernel error analysis
- Separate outputs for each ML algorithm (linear, ridge, random_forest, etc.)

## Metrics

Models are evaluated using:
- **MAPE** (Mean Absolute Percentage Error) - average prediction error
- **Median pred/true ratio** - median of predicted/actual time ratios
- **MAE** (Mean Absolute Error) - average absolute error in milliseconds
- **RMSE** (Root Mean Squared Error) - penalizes large errors
- **Within X% accuracy** - percentage of predictions within 10%, 25%, 50% error

## Requirements

- Python 3.6+
- pandas, numpy
- scikit-learn (for ML models)
